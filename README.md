# Choose Your Own Curriculum

A web application for planning and tracking long term learning goals. Users define topic graphs and upload work samples. The app stores metadata and embeddings to recommend what to study next.

Users can authenticate via email. Use the navigation bar's **Sign in** link to open the `/login` page. Once signed in, the link changes to **Sign out**. The navigation bar also links to the **Uploaded Work** page and the **My Curriculums** page.

The home page provides an overview with links to your students, saved curriculums, uploaded work, and the curriculum generator.

## Tech Stack

- **Next.js** with React Server Components and Server Side Rendering
- **Panda CSS** for styling
- **Mermaid diagrams** rendered with `react-mermaid2`
- **TypeScript** throughout
- **SQLite** database accessed via Drizzle ORM with migrations
- **Vitest** for unit and e2e testing
- **Storybook** for component development
- **NextAuth** for authentication
- **Casbin** for access control
- **LLM Client** uses OpenAI-compatible API with Zod schema validation ([docs](app/src/llm/README.md))
- **GitHub Actions** build Docker images and push to GCR

## Development
This project requires **Node.js 22**. Install it via `nvm`:

```bash
nvm install 22
nvm use 22
```


`pnpm install` automatically rebuilds native modules like `better-sqlite3` for
the current Node version. If you encounter binding errors, you can manually
rebuild with:

```bash
npm rebuild better-sqlite3
```

After installing dependencies, initialize the SQLite database and run pending
migrations:

```bash
pnpm exec drizzle-kit push
```
Running this command will create any tables defined in the schema, including the
`uploaded_work` table. When the `drizzle` folder exists, migrations run
automatically at runtime.


```bash
pnpm install
pnpm dev
```

### Tests

```bash
pnpm test
```

Run end-to-end tests:

```bash
pnpm test:e2e
```

### Storybook

```bash
pnpm storybook
```

## Contributing

Ensure all tests pass and lint using Biome before submitting PRs. See `AGENTS.md` for automation guidelines.
Run `pnpm lint` to check formatting and linting or `pnpm format` to apply fixes.
Remaining tasks and future work are documented in `TASKS.md`.

## Uploaded Work

Authenticated users can upload documents from the **Uploaded Work** page. The server stores the original file, a summary generated by the LLM, and timestamps for when the work was completed and uploaded. Embedding vectors are generated with the `multimodal-embedding-3-small` model and indexed using **sqlite-vec** for fast similarity search. The page lists each of your uploads with its summary for easy review.
New uploads appear immediately in the list with a temporary "Processing..." placeholder while the LLM generates the summary. Any upload errors are shown next to the list.

Math expressions wrapped in `$...$`, `$$...$$`, `\(...\)` or `\[...\]` in summaries are rendered with KaTeX.

## My Curriculums

The **My Curriculums** page lists every topic graph you've generated and saved from the Curriculum Generator page. Click a row to view the full graph. Each entry shows when it was created and which topics were included.

## Student Progress

Click a student's name from the **Students** page to open their progress view. The top of the page shows the selected curriculum along with the topics and rendered DAG. If no curriculum is assigned you can pick one from your saved DAGs. Below the curriculum section all uploaded work for that student is listed using the same interface as the **Uploaded Work** page.

## Tag Generation

Run `pnpm run fetch-tags-for-embeddings` to generate tags for all uploaded work. The script queries every summary, asks the LLM for the top 100 tags, stores them in the database and embeds each tag using the model specified by the `EMBEDDING_MODEL` environment variable (defaults to `text-embedding-3-small`).
